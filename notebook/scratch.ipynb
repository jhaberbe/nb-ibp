{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96bb16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import gamma\n",
    "\n",
    "def polya_gamma_sample(b, c, trunc=100):\n",
    "    \"\"\"\n",
    "    Sample from PG(b, c) using the infinite sum approximation (truncated).\n",
    "\n",
    "    Parameters:\n",
    "        b (float): Shape parameter (often 1).\n",
    "        c (float): Tilt parameter (often logit).\n",
    "        trunc (int): Number of terms in the series to approximate.\n",
    "    \n",
    "    Returns:\n",
    "        float: A single sample from PG(b, c)\n",
    "    \"\"\"\n",
    "    pi = np.pi\n",
    "    out = 0.0\n",
    "    c = np.abs(c)\n",
    "\n",
    "    for n in range(1, trunc + 1):\n",
    "        lambda_n = (n - 0.5)**2 * pi**2 + 0.25 * c**2\n",
    "        out += gamma(b, 1.0) / lambda_n\n",
    "\n",
    "    return 0.5 * out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fca4b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "adata = ad.read_h5ad(\"/home/jhaberbe/Data/choroid-plexus/new_annotations.h5ad\")\n",
    "adata = adata[adata.obs[\"cell_type\"].eq(\"Macrophage\")][::10]\n",
    "X = adata.X.todense()\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180835d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_627603/615902893.py:43: RuntimeWarning: overflow encountered in exp\n",
      "  p = 1.0 / (1.0 + np.exp(-logit))\n",
      "  1%|          | 1/100 [03:05<5:05:23, 185.08s/it]/tmp/ipykernel_627603/615902893.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  term2 = r * np.log(r / (np.exp(mu) + r))\n",
      "/tmp/ipykernel_627603/615902893.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "  term2 = r * np.log(r / (np.exp(mu) + r))\n",
      "/tmp/ipykernel_627603/615902893.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  term3 = x * (mu - np.log(np.exp(mu) + r))\n",
      "/tmp/ipykernel_627603/615902893.py:22: RuntimeWarning: invalid value encountered in multiply\n",
      "  term3 = x * (mu - np.log(np.exp(mu) + r))\n",
      "  3%|â–Ž         | 3/100 [09:40<5:15:08, 194.93s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from scipy.special import gammaln\n",
    "\n",
    "# ---- Input: X assumed provided ----\n",
    "# X: (N, D) Negative Binomial count data\n",
    "K = 10\n",
    "N, D = X.shape\n",
    "\n",
    "# ---- Parameters and latent state initialization ----\n",
    "size_factors = np.log(X.sum(axis=1) / X.sum(axis=1).mean())  # (N,)\n",
    "intercept = np.random.normal(size=D)                         # (D,)\n",
    "dispersion = np.ones(D)                                      # (D,)\n",
    "Z = np.random.rand(N, K) > 0.5                                # (N, K)\n",
    "A = np.random.normal(size=(K, D))                             # (K, D)\n",
    "alpha = 1.0                                                   # IBP concentration\n",
    "\n",
    "# ---- Utility function ----\n",
    "def nb_log_likelihood(x, mu, r):\n",
    "    term1 = gammaln(x + r) - gammaln(r) - gammaln(x + 1)\n",
    "    term2 = r * np.log(r / (np.exp(mu) + r))\n",
    "    term3 = x * (mu - np.log(np.exp(mu) + r))\n",
    "    return (term1 + term2 + term3).sum()\n",
    "\n",
    "# ---- Gibbs sampling ----\n",
    "for gibbs_iter in trange(100):\n",
    "    # --- Sample Z[n, k] ---\n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            Z[n, k] = 0  # temporarily set to 0\n",
    "\n",
    "            m_k = Z[:, k].sum()\n",
    "            prior_z1 = (m_k + alpha / K) / (N + alpha / K)\n",
    "            prior_z0 = 1.0 - prior_z1\n",
    "\n",
    "            phi_0 = size_factors[n] + intercept + Z[n] @ A\n",
    "            phi_1 = phi_0 + A[k]\n",
    "\n",
    "            ll_0 = nb_log_likelihood(X[n], phi_0, dispersion)\n",
    "            ll_1 = nb_log_likelihood(X[n], phi_1, dispersion)\n",
    "\n",
    "            logit = ll_1 - ll_0 + np.log(prior_z1) - np.log(prior_z0)\n",
    "            p = 1.0 / (1.0 + np.exp(-logit))\n",
    "            Z[n, k] = np.random.rand() < p\n",
    "\n",
    "    # --- Sample A[k] via PG augmentation ---\n",
    "    phi = size_factors[:, None] + intercept[None, :] + Z @ A\n",
    "    omega = polya_gamma_sample(X + dispersion, phi)\n",
    "    kappa = X - 0.5 * dispersion[None, :]\n",
    "\n",
    "    for k in range(K):\n",
    "        Z_k = Z[:, k]                          # (N,)\n",
    "        phi_wo_k = phi - np.outer(Z_k, A[k])  # Remove A[k] contribution\n",
    "\n",
    "        mu_k = np.zeros(D)\n",
    "        sigma_k = np.zeros(D)\n",
    "\n",
    "        for d in range(D):\n",
    "            w = omega[:, d]\n",
    "            residual = kappa[:, d] - w * phi_wo_k[:, d]\n",
    "            precision = np.sum(w * Z_k**2)\n",
    "            sigma2 = 1.0 / precision if precision > 1e-12 else 1e12\n",
    "            mu = sigma2 * np.sum(Z_k * residual)\n",
    "            mu_k[d] = mu\n",
    "            sigma_k[d] = np.sqrt(sigma2)\n",
    "\n",
    "        A[k] = np.random.normal(loc=mu_k, scale=sigma_k)\n",
    "\n",
    "    def propose_r(r_old, step_size=0.1):\n",
    "        log_r_new = np.log(r_old) + np.random.normal(scale=step_size)\n",
    "        return np.exp(log_r_new)\n",
    "\n",
    "    def log_nb_likelihood_column(x, r, phi):\n",
    "        mu = np.exp(phi)\n",
    "        term1 = gammaln(x + r) - gammaln(r) - gammaln(x + 1)\n",
    "        term2 = r * np.log(r / (mu + r))\n",
    "        term3 = x * (phi - np.log(mu + r))\n",
    "        return term1 + term2 + term3\n",
    "\n",
    "    # Inside Gibbs loop:\n",
    "    for d in range(D):\n",
    "        r_old = dispersion[d]\n",
    "        r_new = propose_r(r_old)\n",
    "\n",
    "        ll_old = log_nb_likelihood_column(X[:, d], r_old, phi[:, d]).sum()\n",
    "        ll_new = log_nb_likelihood_column(X[:, d], r_new, phi[:, d]).sum()\n",
    "\n",
    "        prior_old = -r_old  # exponential prior with rate=1\n",
    "        prior_new = -r_new\n",
    "\n",
    "        log_accept_ratio = ll_new + prior_new - ll_old - prior_old\n",
    "\n",
    "        if np.log(np.random.rand()) < log_accept_ratio:\n",
    "            dispersion[d] = r_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c40b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
